{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import sys\n",
    "\n",
    "import knn_gpu\n",
    "importlib.reload(knn_gpu)\n",
    "\n",
    "def run_knn_features(feature_vectors, test_vectors=None, k=5, flat=True,\n",
    "                     verbose=False, dist=False, gpu=False):\n",
    "    nb, d = feature_vectors.shape\n",
    "    if type(test_vectors) is not np.ndarray:\n",
    "        if flat:\n",
    "            D, I = knn_gpu.knn_flat(feature_vectors, feature_vectors, d, k, verbose, gpu)\n",
    "        else:\n",
    "            D, I = knn_gpu.knn_ivf(feature_vectors, feature_vectors, d, k, verbose, gpu)\n",
    "    else:\n",
    "        if flat:\n",
    "            D, I = knn_gpu.knn_flat(feature_vectors, test_vectors, d, k, verbose, gpu)\n",
    "        else:\n",
    "            D, I = knn_gpu.knn_ivf(feature_vectors, test_vectors, d, k, verbose, gpu)\n",
    "\n",
    "    if dist:\n",
    "        return D, I \n",
    "    else:\n",
    "        return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import faiss\n",
    "\n",
    "class knn_query():\n",
    "    \"\"\"\n",
    "    Class for kNN query using FAISS\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dims, xb, labels):\n",
    "        \"\"\" Constructor\n",
    "            Args:\n",
    "                dims = number of dimensions\n",
    "                index = FAISS index object\n",
    "                xb = numpy array of feature vectors\n",
    "                labels = dict, index to frame path mapping\n",
    "                isTrained = boolean, is the index trained?\n",
    "        \"\"\"\n",
    "        self.dims = dims\n",
    "        self.index = None\n",
    "        self.xb = xb\n",
    "        self.labels = labels\n",
    "        self.isTrained = False\n",
    "\n",
    "    def train_knn_index(self):\n",
    "        \"\"\"\n",
    "        This function trains the index using the extracted features so that\n",
    "        kNN query can be performed. It just needs to be run with the extracted\n",
    "        features.\n",
    "        \"\"\"\n",
    "        # build the index\n",
    "        s_time = time.time()\n",
    "        self.index = faiss.IndexFlatL2(self.dims)\n",
    "        self.isTrained = True\n",
    "        # add feature vectors to the index\n",
    "        print('Adding feature vectors to the index...')\n",
    "        self.index.add(self.xb)\n",
    "        e_time = time.time()\n",
    "        index_time = round(e_time - s_time, 3)\n",
    "        print('{} feature vectors added'.format(self.index.ntotal))\n",
    "        print('Index finished in {}s'.format(index_time))\n",
    "\n",
    "    def perform_query(self, xq, k):\n",
    "        \"\"\"\n",
    "        This method performs the kNN query on trained index of the\n",
    "        FAISS index object.\n",
    "        \"\"\"\n",
    "        if not self.isTrained:\n",
    "            print('You must train the index first!')\n",
    "        else:\n",
    "            # perform the query\n",
    "            print('Performing {} nearest neighbor search...'.format(k))\n",
    "            s_time = time.time()\n",
    "            D, I = self.index.search(x=xq, k=k)\n",
    "            e_time = time.time()\n",
    "            query_time = round(e_time - s_time, 3)\n",
    "            return D, I, query_time\n",
    "\n",
    "\n",
    "def output_results(I, labels, query_image, query_time):\n",
    "    print('\\nQuery Completed in {}s'.format(query_time))\n",
    "    print('\\nQuery Frame:\\n', query_image)\n",
    "    print('\\n')\n",
    "    print('Top Similar Frames:')\n",
    "    for i, ind in enumerate(I[0]):\n",
    "        print(i+1, ': ', labels[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Extracted Features File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracted features files path\n",
    "extracted_features_path = '/mnt/e/3dcnn_features/'\n",
    "extracted_features_filename = 'ucf101_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load extracted features\n",
    "file = open(os.path.join(extracted_features_path, extracted_features_filename),'rb')\n",
    "features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.json', 'r') as f:\n",
    "    features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "ind2video_mapping = {}\n",
    "video2ind_mapping = {}\n",
    "for i, video in enumerate(features):\n",
    "    feature_vectors.append(video['clips'][0]['features'])\n",
    "    ind2video_mapping[i] = video['video']\n",
    "    video2ind_mapping[video['video']] = i\n",
    "    \n",
    "feature_vectors = np.array(feature_vectors)\n",
    "feature_vectors = feature_vectors.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'v_ApplyEyeMakeup_g02_c03.avi',\n",
       " 1: 'v_Kayaking_g17_c06.avi',\n",
       " 2: 'v_ApplyEyeMakeup_g04_c02.avi',\n",
       " 3: 'v_LongJump_g11_c02.avi'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2video_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test kNN on Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_ApplyEyeMakeup_g02_c03.avi': 0,\n",
       " 'v_Kayaking_g17_c06.avi': 1,\n",
       " 'v_ApplyEyeMakeup_g04_c02.avi': 2,\n",
       " 'v_LongJump_g11_c02.avi': 3}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video2ind_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding feature vectors to the index...\n",
      "4 feature vectors added\n",
      "Index finished in 0.0s\n"
     ]
    }
   ],
   "source": [
    "# test CPU knn\n",
    "d = 512\n",
    "k = 3\n",
    "query = knn_query(d, feature_vectors, ind2video_mapping)\n",
    "query.train_knn_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "v_Kayaking_g17_c06.avi\n",
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "# test input \n",
    "n_videos = len(features)\n",
    "# np.random.seed(0)\n",
    "n = np.random.randint(0, n_videos)\n",
    "print(n)\n",
    "\n",
    "# get query vector\n",
    "query_features = np.reshape(feature_vectors[n, :].astype(np.float32), (1, -1))\n",
    "print(ind2video_mapping[n])\n",
    "print(query_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 3 nearest neighbor search...\n",
      "\n",
      "Query Completed in 0.0s\n",
      "\n",
      "Query Frame:\n",
      " v_Kayaking_g17_c06.avi\n",
      "\n",
      "\n",
      "Top Similar Frames:\n",
      "1 :  v_Kayaking_g17_c06.avi\n",
      "2 :  v_ApplyEyeMakeup_g04_c02.avi\n",
      "3 :  v_ApplyEyeMakeup_g02_c03.avi\n"
     ]
    }
   ],
   "source": [
    "# CPU kNN\n",
    "D, I, q_time = query.perform_query(query_features, k)\n",
    "output_results(I, ind2video_mapping, ind2video_mapping[n], q_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-355-455e3d5edd06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mq_time_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mI_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_knn_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2video_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2video_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_time_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "# GPU kNN\n",
    "q_time_gpu = None\n",
    "I_gpu = run_knn_features(feature_vectors=feature_vectors, test_vectors=query_features, gpu=False)\n",
    "output_results(I_gpu, ind2video_mapping, ind2video_mapping[n], q_time_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_3dcnn_ucf_video(video_path, feature_vectors, k=5, dist=False, verbose=False):\n",
    "    \"\"\"\n",
    "    This function extracts features from the query video and performs kNN similarity search.\n",
    "    \"\"\"\n",
    "    try:\n",
    "#         query_features = extract_features_from_vid(video_path)\n",
    "        distances, feature_indices = run_knn_features(feature_vectors, test_vectors=query_features,\n",
    "                                                    k=k, dist=True)\n",
    "        print(distances)\n",
    "        if verbose:\n",
    "            print(color_labels[feature_indices][0])\n",
    "        if dist:\n",
    "            return list(distances[0]), list(feature_vectors[feature_indices][0])\n",
    "        else:\n",
    "            return list(feature_vectors[feature_indices][0])\n",
    "    except:\n",
    "        print('No video found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.      321.06046 376.89996]]\n"
     ]
    }
   ],
   "source": [
    "cnn3d_dist, cnn3d_indices = similar_3dcnn_ucf_video(True, feature_vectors, k=3, dist=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 321.06046, 376.89996]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(cnn3d_dist)\n",
    "print(len(cnn3d_indices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
