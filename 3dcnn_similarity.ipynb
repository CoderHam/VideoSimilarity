{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import sys\n",
    "\n",
    "import knn_gpu\n",
    "importlib.reload(knn_gpu)\n",
    "\n",
    "def run_knn_features(feature_vectors, test_vectors=None, k=5, flat=True,\n",
    "                     verbose=False, dist=False, gpu=False):\n",
    "    nb, d = feature_vectors.shape\n",
    "    if type(test_vectors) is not np.ndarray:\n",
    "        if flat:\n",
    "            D, I = knn_gpu.knn_flat(feature_vectors, feature_vectors, d, k, verbose, gpu)\n",
    "        else:\n",
    "            D, I = knn_gpu.knn_ivf(feature_vectors, feature_vectors, d, k, verbose, gpu)\n",
    "    else:\n",
    "        if flat:\n",
    "            D, I = knn_gpu.knn_flat(feature_vectors, test_vectors, d, k, verbose, gpu)\n",
    "        else:\n",
    "            D, I = knn_gpu.knn_ivf(feature_vectors, test_vectors, d, k, verbose, gpu)\n",
    "\n",
    "    if dist:\n",
    "        return D, I \n",
    "    else:\n",
    "        return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import faiss\n",
    "\n",
    "class knn_query():\n",
    "    \"\"\"\n",
    "    Class for kNN query using FAISS\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dims, xb, labels):\n",
    "        \"\"\" Constructor\n",
    "            Args:\n",
    "                dims = number of dimensions\n",
    "                index = FAISS index object\n",
    "                xb = numpy array of feature vectors\n",
    "                labels = dict, index to frame path mapping\n",
    "                isTrained = boolean, is the index trained?\n",
    "        \"\"\"\n",
    "        self.dims = dims\n",
    "        self.index = None\n",
    "        self.xb = xb\n",
    "        self.labels = labels\n",
    "        self.isTrained = False\n",
    "\n",
    "    def train_knn_index(self):\n",
    "        \"\"\"\n",
    "        This function trains the index using the extracted features so that\n",
    "        kNN query can be performed. It just needs to be run with the extracted\n",
    "        features.\n",
    "        \"\"\"\n",
    "        # build the index\n",
    "        s_time = time.time()\n",
    "        self.index = faiss.IndexFlatL2(self.dims)\n",
    "        self.isTrained = True\n",
    "        # add feature vectors to the index\n",
    "        print('Adding feature vectors to the index...')\n",
    "        self.index.add(self.xb)\n",
    "        e_time = time.time()\n",
    "        index_time = round(e_time - s_time, 3)\n",
    "        print('{} feature vectors added'.format(self.index.ntotal))\n",
    "        print('Index finished in {}s'.format(index_time))\n",
    "\n",
    "    def perform_query(self, xq, k):\n",
    "        \"\"\"\n",
    "        This method performs the kNN query on trained index of the\n",
    "        FAISS index object.\n",
    "        \"\"\"\n",
    "        if not self.isTrained:\n",
    "            print('You must train the index first!')\n",
    "        else:\n",
    "            # perform the query\n",
    "            print('Performing {} nearest neighbor search...'.format(k))\n",
    "            s_time = time.time()\n",
    "            D, I = self.index.search(x=xq, k=k)\n",
    "            e_time = time.time()\n",
    "            query_time = round(e_time - s_time, 3)\n",
    "            return D, I, query_time\n",
    "\n",
    "\n",
    "def output_results(I, labels, query_image, query_time):\n",
    "    print('\\nQuery Completed in {}s'.format(query_time))\n",
    "    print('\\nQuery Frame:\\n', query_image)\n",
    "    print('\\n')\n",
    "    print('Top Similar Frames:')\n",
    "    for i, ind in enumerate(I[0]):\n",
    "        print(i+1, ': ', labels[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert Extracted Features File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracted features files path\n",
    "extracted_features_path = '/mnt/e/3dcnn_features/'\n",
    "extracted_features_filename = 'ucf101_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load extracted features\n",
    "file = open(os.path.join(extracted_features_path, extracted_features_filename),'rb')\n",
    "features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "ind2video_mapping = {}\n",
    "video2ind_mapping = {}\n",
    "for i, video in enumerate(features):\n",
    "    feature_vectors.append(video['clips'][0]['features'])\n",
    "    ind2video_mapping[i] = video['video']\n",
    "    video2ind_mapping[video['video']] = i\n",
    "    \n",
    "feature_vectors = np.array(feature_vectors)\n",
    "feature_vectors = feature_vectors.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test kNN on Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding feature vectors to the index...\n",
      "13320 feature vectors added\n",
      "Index finished in 0.007s\n"
     ]
    }
   ],
   "source": [
    "# test CPU knn\n",
    "d = 512\n",
    "k = 5\n",
    "query = knn_query(d, feature_vectors, ind2video_mapping)\n",
    "query.train_knn_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536\n",
      "v_ParallelBars_g15_c02.avi\n",
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "# test input \n",
    "n_videos = len(features)\n",
    "# np.random.seed(0)\n",
    "n = np.random.randint(0, n_videos)\n",
    "print(n)\n",
    "\n",
    "# get query vector\n",
    "query_features = np.reshape(feature_vectors[n, :].astype(np.float32), (1, -1))\n",
    "print(ind2video_mapping[n])\n",
    "print(query_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5 nearest neighbor search...\n",
      "\n",
      "Query Completed in 0.004s\n",
      "\n",
      "Query Frame:\n",
      " v_ParallelBars_g15_c02.avi\n",
      "\n",
      "\n",
      "Top Similar Frames:\n",
      "1 :  v_ParallelBars_g15_c02.avi\n",
      "2 :  v_ParallelBars_g15_c04.avi\n",
      "3 :  v_ParallelBars_g15_c03.avi\n",
      "4 :  v_ParallelBars_g15_c01.avi\n",
      "5 :  v_FloorGymnastics_g24_c01.avi\n"
     ]
    }
   ],
   "source": [
    "# CPU kNN\n",
    "D, I, q_time = query.perform_query(query_features, k)\n",
    "output_results(I, ind2video_mapping, ind2video_mapping[n], q_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Completed in Nones\n",
      "\n",
      "Query Frame:\n",
      " v_ParallelBars_g15_c02.avi\n",
      "\n",
      "\n",
      "Top Similar Frames:\n",
      "1 :  v_ParallelBars_g15_c02.avi\n",
      "2 :  v_ParallelBars_g15_c04.avi\n",
      "3 :  v_ParallelBars_g15_c03.avi\n",
      "4 :  v_ParallelBars_g15_c01.avi\n",
      "5 :  v_FloorGymnastics_g24_c01.avi\n"
     ]
    }
   ],
   "source": [
    "# GPU kNN\n",
    "q_time_gpu = None\n",
    "I_gpu = run_knn_features(feature_vectors=feature_vectors, test_vectors=query_features, gpu=False)\n",
    "output_results(I_gpu, ind2video_mapping, ind2video_mapping[n], q_time_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
