{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "# import torch and other libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from IPython.display import display # to display images\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# other imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "resnet_model = models.resnet18(pretrained=True)\n",
    "alexnet_model = models.alexnet(pretrained=True)\n",
    "# Use the model object to select the desired layer\n",
    "resnet_layer = resnet_model._modules.get('avgpool')\n",
    "alexnet_layer = alexnet_model._modules.get('classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "resnet_model.eval()\n",
    "alexnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image scaler to 224 x 224 pixels\n",
    "scaler = transforms.Scale((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vector(image_name, model):\n",
    "    # 1. Load the image with Pillow library\n",
    "    img = Image.open(image_name)\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    if model == 'resnet':\n",
    "        # 3. Create a vector of zeros that will hold our feature vector\n",
    "        #    The 'avgpool' layer has an output size of 512\n",
    "        my_embedding = torch.zeros(512)\n",
    "        # 4. Define a function that will copy the output of a layer\n",
    "        def copy_data(m, i, o):\n",
    "            my_embedding.copy_(o.data)\n",
    "        # 5. Attach that function to our selected layer\n",
    "        h = resnet_layer.register_forward_hook(copy_data)\n",
    "        # 6. Run the model on our transformed image\n",
    "        resnet_model(t_img)\n",
    "        h.remove()\n",
    "    elif model == 'alexnet':\n",
    "        print('using alexnet...')\n",
    "        # 3. Create a vector of zeros that will hold our feature vector\n",
    "        #    The 'classifier' layer has an output size of 1000\n",
    "        my_embedding = torch.zeros(1000)\n",
    "        def copy_data(m, i, o):\n",
    "            my_embedding.copy_(o.data)\n",
    "        # 5. Attach that function to our selected layer\n",
    "        h = alexnet_layer.register_forward_hook(copy_data)\n",
    "        # 6. Run the model on our transformed image\n",
    "        alexnet_model(t_img)\n",
    "        h.remove()\n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/images/'\n",
    "img1 = DATA_PATH + 'golden1.jpg'\n",
    "# img2 = DATA_PATH + 'golden2.jpg'\n",
    "img2 = DATA_PATH + 'cat1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanbae/anaconda/envs/pytorch36/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trials: 10\n",
      "Image 1 Feature Vector Genration Time: 0.012s\n",
      "Image 2 Feature Vector Genration Time: 0.011s\n",
      "\n",
      "Corpus Size=3000000, Frames per Video=10\n",
      "Corpus Processing Time: 100.0 hrs, or 4.167 days\n"
     ]
    }
   ],
   "source": [
    "# get feature vectors from resnet18\n",
    "n_trials = 10\n",
    "img1_resnet_times = []\n",
    "img2_resnet_times = []\n",
    "\n",
    "# get feature vectors n_trial times each and average\n",
    "for i in range(n_trials):\n",
    "    # image 1\n",
    "    t_start_img1 = time.time()\n",
    "    img1_vector = get_vector(img1, 'resnet')\n",
    "    img1_resnet_times.append(time.time() - t_start_img1)\n",
    "    # image 2\n",
    "    t_start_img2 = time.time()\n",
    "    img2_vector = get_vector(img2, 'resnet')\n",
    "    img2_resnet_times.append(time.time() - t_start_img2)\n",
    "\n",
    "# output results\n",
    "t_mean_img1_resnet = round(np.mean(img1_resnet_times)/n_trials, 3)\n",
    "t_mean_img2_resnet = round(np.mean(img2_resnet_times)/n_trials, 3)\n",
    "print('Number of Trials: {}'.format(n_trials))\n",
    "print('Image 1 Feature Vector Genration Time: {}s'.format(t_mean_img1_resnet))\n",
    "print('Image 2 Feature Vector Genration Time: {}s'.format(t_mean_img2_resnet))\n",
    "\n",
    "n_frames = 10\n",
    "n_corpus = 3e6\n",
    "t_corpus = round(t_mean_img1_resnet*n_frames*n_corpus/3600, 3)\n",
    "print('\\nCorpus Size={}, Frames per Video={}'.format(int(n_corpus), n_frames))\n",
    "print('Corpus Processing Time: {} hrs, or {} days'.format(t_corpus, round(t_corpus/24, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine similarity: \n",
      " 0.5390\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch Cosine Similarity\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos_sim = cos(img1_vector.unsqueeze(0),\n",
    "              img2_vector.unsqueeze(0))\n",
    "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test = [np.array(img1_vector), np.array(img2_vector)]\n",
    "features_test = np.array(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.264336  , 1.0769418 , 0.7329236 , ..., 0.42827195, 3.0381756 ,\n",
       "        0.05954078],\n",
       "       [0.10493794, 0.26243308, 0.761945  , ..., 1.0433315 , 0.18960439,\n",
       "        0.7961156 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet 18 experiments show that feature vector image generation takes aobut 1/100th of a second. This means over 45 days to process 3 million videos with 100 sampled images each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get feature vectors from alexnet\n",
    "# img1_vector_a = get_vector(img1, 'alexnet')\n",
    "# img2_vector_a = get_vector(img2, 'alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512)\n"
     ]
    }
   ],
   "source": [
    "img1_vec = np.array(img1_vector)\n",
    "img2_vec = np.array(img2_vector)\n",
    "vec = np.array([img1_vec, img2_vec])\n",
    "print(vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames extraction from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FFMPEGFrames' from '/Users/ryanbae/Dropbox/uw_data_science/fall_2018/data590_capstone1/VideoSimilarity/FFMPEGFrames.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import FFMPEGFrames\n",
    "import shutil\n",
    "import importlib\n",
    "from ffprobe3 import FFProbe\n",
    "importlib.reload(FFMPEGFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/videos/work/7.mp4 13s (0.7692307692307693)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-042da7ea6300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resnet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# delete rest of the files after extracting image features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-042da7ea6300>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resnet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# delete rest of the files after extracting image features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_vector' is not defined"
     ]
    }
   ],
   "source": [
    "videos_path = 'data/videos'\n",
    "delete = True\n",
    "features = {}\n",
    "\n",
    "# loop through all the videos\n",
    "i = 0\n",
    "for path, subdirs, files in os.walk(videos_path):\n",
    "    for name in files:\n",
    "        if i < 2:\n",
    "            # extract frames from videos\n",
    "            video_length = int(float(FFProbe(os.path.join(path, name)).video[0].duration)) + 1\n",
    "            n_frames = 10\n",
    "            fps = n_frames/video_length\n",
    "            video_path = os.path.join(path, name)\n",
    "            print(os.path.join(path, name) + ' ' + str(video_length) + 's ' + '(' + str(fps) + ')')\n",
    "            f = FFMPEGFrames.FFMPEGFrames(\"data/video_frames/\")\n",
    "            f.extract_frames(os.path.join(path, name), fps)\n",
    "            i += 1\n",
    "            # get feature vectors for each frame image\n",
    "            frames_path = f.full_output\n",
    "            frames = os.listdir(frames_path)\n",
    "            model = 'resnet'\n",
    "            features[video_path] = [get_vector(os.path.join(frames_path, frame), model) for frame in frames]\n",
    "            # delete rest of the files after extracting image features\n",
    "            if delete:\n",
    "                shutil.rmtree(f.full_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data/videos/0.mp4': array([1, 9, 1])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = {'data/videos/0.mp4':np.array([1, 9, 1])}\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_path = 'data/videos/0.mp4'\n",
    "data = np.array([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"0.mp4\": shape (1, 1, 1), type \"<f4\">"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File(\"test.hdf5\", \"w\")\n",
    "f.create_dataset(video_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = h5py.File('features.hdf5', 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(<HDF5 file \"features.hdf5\" (mode r+)>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['videos']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all groups\n",
    "print(\"Keys: %s\" % f1.keys())\n",
    "a_group_key = list(f1.keys())[0]\n",
    "\n",
    "# # Get the data\n",
    "data = list(f1[a_group_key])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(<HDF5 file \"features.hdf5\" (mode r+)>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_names = f1.keys()\n",
    "data_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.32818490e-01, 2.65119839e+00, 2.25517464e+00, 5.31009197e-01,\n",
       "       2.40465418e-01, 7.56578565e-01, 2.76097804e-01, 8.12232673e-01,\n",
       "       1.53614259e+00, 4.39417481e-01, 1.83384049e+00, 1.24493694e+00,\n",
       "       8.32031786e-01, 8.92312974e-02, 8.66587996e-01, 1.57974100e+00,\n",
       "       4.57243264e-01, 1.04864717e+00, 1.51076984e+00, 4.40074623e-01,\n",
       "       4.61099893e-02, 7.44705975e-01, 5.53882003e-01, 8.90647709e-01,\n",
       "       1.29319811e+00, 1.43117678e+00, 3.04760993e-01, 4.97556180e-01,\n",
       "       5.35472557e-02, 9.15293813e-01, 6.32018328e-01, 9.95632410e-01,\n",
       "       2.99119726e-02, 5.26447408e-02, 2.33933151e-01, 7.16903269e-01,\n",
       "       2.32425952e+00, 1.82374448e-01, 2.23342061e+00, 1.13279068e+00,\n",
       "       7.23410726e-01, 1.07103217e+00, 7.12132573e-01, 1.27874923e+00,\n",
       "       3.76490474e+00, 2.29532570e-01, 1.01108634e+00, 4.89228576e-01,\n",
       "       2.04637671e+00, 3.19082618e-01, 1.20602441e+00, 6.69650495e-01,\n",
       "       6.35978222e-01, 1.92972556e-01, 1.11094221e-01, 1.06720829e+00,\n",
       "       1.07549608e+00, 7.18654096e-01, 1.06056952e+00, 1.46130943e+00,\n",
       "       4.64607835e-01, 7.15717822e-02, 1.68986380e-01, 1.62568271e-01,\n",
       "       1.31470251e+00, 1.35511172e+00, 2.14553094e+00, 1.44296718e+00,\n",
       "       1.43609166e+00, 2.32890561e-01, 4.04663861e-01, 1.82107830e+00,\n",
       "       1.26940429e-01, 1.38977319e-01, 1.00144315e+00, 8.40740204e-01,\n",
       "       6.61150038e-01, 2.12355152e-01, 6.92971721e-02, 5.59108973e-01,\n",
       "       8.68943274e-01, 8.27321708e-01, 1.19377553e+00, 7.75364995e-01,\n",
       "       1.82021022e+00, 1.00795226e-03, 1.30823517e+00, 2.68454291e-02,\n",
       "       4.34435272e+00, 4.68633366e+00, 1.07427084e+00, 7.43489921e-01,\n",
       "       3.31559122e-01, 5.16825438e-01, 6.41339421e-01, 1.61584365e+00,\n",
       "       1.77348518e+00, 2.50609159e+00, 1.04412019e+00, 2.28542614e+00,\n",
       "       1.14344501e+00, 7.55587578e-01, 1.26895702e+00, 6.81294918e-01,\n",
       "       5.83911657e-01, 1.09771974e-02, 5.44112563e-01, 7.61915296e-02,\n",
       "       1.30432451e+00, 2.79601622e+00, 6.99721003e+00, 2.46567354e-01,\n",
       "       5.59009053e-02, 2.19906116e+00, 2.98407388e+00, 1.69363344e+00,\n",
       "       1.00100137e-01, 5.72565906e-02, 3.88327450e-01, 5.92616022e-01,\n",
       "       8.99660826e-01, 2.81346035e+00, 3.72798055e-01, 5.02515957e-02,\n",
       "       1.25073478e-01, 2.68664837e-01, 2.05361575e-01, 1.04709387e+00,\n",
       "       1.31100011e+00, 1.48239887e+00, 7.52782362e-05, 1.11211705e+00,\n",
       "       1.57069814e+00, 4.41701114e-01, 1.92533746e-01, 6.39932379e-02,\n",
       "       7.07621098e-01, 8.60509992e-01, 8.03129673e-01, 5.53797543e-01,\n",
       "       4.50109124e-01, 2.60376841e-01, 1.78891599e+00, 2.78778100e+00,\n",
       "       6.66124046e-01, 1.18939802e-01, 4.36113656e-01, 4.23570096e-01,\n",
       "       1.31498253e+00, 1.36274564e+00, 1.95908749e+00, 8.66003335e-02,\n",
       "       2.09252453e+00, 7.07754552e-01, 3.81376982e+00, 6.28968477e-01,\n",
       "       4.49889362e-01, 1.67753339e+00, 6.31039083e-01, 1.01323414e+00,\n",
       "       7.01026440e-01, 1.42914727e-01, 3.97341400e-01, 3.50759292e+00,\n",
       "       7.26052821e-01, 6.24171615e-01, 1.13027406e+00, 4.95580554e-01,\n",
       "       2.15716720e+00, 4.54496816e-02, 7.28378668e-02, 1.34145212e+00,\n",
       "       2.65838838e+00, 1.28214777e-01, 3.24605393e+00, 2.49337840e+00,\n",
       "       6.32892996e-02, 2.04577699e-01, 5.53254247e-01, 2.40114808e-01,\n",
       "       1.85601637e-01, 4.94052380e-01, 9.55023646e-01, 9.74633694e-01,\n",
       "       1.97732401e+00, 6.54532135e-01, 3.29720199e-01, 1.18949354e+00,\n",
       "       9.99435902e-01, 1.70302367e+00, 4.62538779e-01, 2.34040573e-01,\n",
       "       3.26630282e+00, 1.08229399e+00, 1.46983576e+00, 5.55736432e-03,\n",
       "       1.47793263e-01, 1.92436576e+00, 7.02374816e-01, 5.82581878e-01,\n",
       "       5.35403252e-01, 7.03210533e-01, 8.03023726e-02, 3.45298983e-02,\n",
       "       3.33661735e-01, 5.44697344e-01, 1.22120094e+00, 8.59542370e-01,\n",
       "       5.90896130e-01, 1.06396355e-01, 1.00333698e-01, 4.67542768e-01,\n",
       "       1.92770016e+00, 1.28203690e+00, 9.76274669e-01, 1.95677841e+00,\n",
       "       6.34494543e-01, 1.00080812e+00, 1.61341876e-01, 1.57766521e+00,\n",
       "       7.85470307e-01, 6.31307840e-01, 4.37871329e-02, 1.17338860e+00,\n",
       "       1.12192130e+00, 8.95747066e-01, 8.35995138e-01, 1.67557329e-01,\n",
       "       8.33053980e-03, 3.76381963e-01, 2.48217034e+00, 5.61599672e-01,\n",
       "       1.66794431e+00, 1.88219652e-01, 7.69389510e-01, 7.64114559e-01,\n",
       "       6.95339262e-01, 3.87598127e-01, 3.82684320e-01, 2.20510691e-01,\n",
       "       1.27642119e+00, 4.20133978e-01, 4.00159478e-01, 9.19412524e-02,\n",
       "       2.38132000e+00, 1.46332192e+00, 7.59576321e-01, 7.22564459e-01,\n",
       "       5.36144972e-01, 2.15912253e-01, 5.46461232e-02, 6.62494659e-01,\n",
       "       1.00854075e+00, 4.96472687e-01, 9.84971941e-01, 1.87584186e+00,\n",
       "       2.45008492e+00, 2.33219892e-01, 2.11287761e+00, 2.71979362e-01,\n",
       "       8.28764081e-01, 4.52428073e-01, 5.91371119e-01, 4.68655407e-01,\n",
       "       5.70981987e-02, 6.08063459e-01, 2.73468047e-01, 1.35588288e+00,\n",
       "       3.10346447e-02, 1.22392726e+00, 1.58033812e+00, 6.53169572e-01,\n",
       "       1.62472486e+00, 1.88633263e-01, 2.50971937e+00, 8.55838358e-01,\n",
       "       1.29175842e+00, 1.02672338e+00, 2.18599007e-01, 1.64991006e-01,\n",
       "       2.22930282e-01, 1.56475082e-02, 3.00880098e+00, 1.26742256e+00,\n",
       "       2.40922809e-01, 2.51922058e-04, 6.06866539e-01, 2.29098606e+00,\n",
       "       1.02912784e+00, 5.81536174e-01, 2.48879862e+00, 1.93621659e+00,\n",
       "       1.87625259e-01, 5.14693022e-01, 1.21245697e-01, 2.46049571e+00,\n",
       "       1.52139783e+00, 6.35757148e-01, 1.20463037e+00, 6.99649215e-01,\n",
       "       5.73376119e-01, 3.05434972e-01, 3.10815156e-01, 2.15609980e+00,\n",
       "       1.48520374e+00, 1.70885217e+00, 8.22217315e-02, 1.62084913e+00,\n",
       "       8.84139776e-01, 3.75848532e-01, 1.81481335e-02, 2.60080248e-01,\n",
       "       2.53489065e+00, 6.17716014e-01, 1.54252529e+00, 1.20284259e+00,\n",
       "       8.98240864e-01, 8.18116784e-01, 7.19794810e-01, 1.11599550e-01,\n",
       "       1.54456675e-01, 4.73889053e-01, 5.43689355e-02, 2.77646519e-02,\n",
       "       8.75496745e-01, 4.30662155e-01, 2.27647766e-01, 5.21683872e-01,\n",
       "       5.89950860e-01, 7.61201024e-01, 1.69443357e+00, 3.44769239e-01,\n",
       "       7.16698468e-01, 2.78061554e-02, 2.85580248e-01, 3.71799432e-02,\n",
       "       3.74642342e-01, 1.64053217e-01, 3.79297018e-01, 8.36138368e-01,\n",
       "       1.49548575e-01, 7.15685964e-01, 3.85157652e-02, 5.72338164e-01,\n",
       "       1.29151368e+00, 3.55025977e-01, 1.22260414e-02, 9.85221148e-01,\n",
       "       1.36906743e-01, 1.15761364e+00, 3.72384644e+00, 2.76519746e-01,\n",
       "       1.90028977e+00, 1.78791478e-01, 7.96186268e-01, 6.39475405e-01,\n",
       "       4.82421249e-01, 4.38064694e-01, 2.21663401e-01, 3.68184954e-01,\n",
       "       5.72181582e-01, 8.73788238e-01, 1.36094248e+00, 5.61703801e-01,\n",
       "       1.68855965e+00, 2.84188151e-01, 3.44495237e-01, 2.84127533e-01,\n",
       "       1.92133319e+00, 4.82510090e-01, 1.94580257e-02, 5.69136798e-01,\n",
       "       4.01477426e-01, 2.04224801e+00, 7.36808181e-01, 7.56595016e-01,\n",
       "       1.22815180e+00, 1.03120434e+00, 1.26525414e+00, 1.11679709e+00,\n",
       "       9.73359406e-01, 2.29169464e+00, 6.34607732e-01, 1.86912167e+00,\n",
       "       1.89771920e-01, 5.24284661e-01, 1.20581937e+00, 2.81018252e-03,\n",
       "       9.80048358e-01, 9.53562111e-02, 5.86737394e-01, 2.95890450e-01,\n",
       "       4.71977741e-01, 1.34320974e-01, 2.37778163e+00, 8.26175392e-01,\n",
       "       2.50190467e-01, 1.14454389e+00, 9.65064824e-01, 8.59814942e-01,\n",
       "       4.30575520e-01, 3.86469096e-01, 1.38410938e+00, 8.19673479e-01,\n",
       "       2.47298408e+00, 6.36728823e-01, 2.08795476e+00, 2.02980924e+00,\n",
       "       1.34270281e-01, 3.73462915e+00, 1.08027685e+00, 2.02456999e+00,\n",
       "       5.75024128e-01, 2.31172681e-01, 9.03022289e-01, 9.62774873e-01,\n",
       "       1.69781661e+00, 2.20589973e-02, 5.95095009e-02, 3.07284713e-01,\n",
       "       8.09312344e-01, 8.41216370e-02, 2.19039893e+00, 2.42520332e+00,\n",
       "       1.45801950e+00, 1.28663152e-01, 2.88013101e-01, 1.77666926e+00,\n",
       "       1.01607418e+00, 9.27289277e-02, 2.00053644e+00, 8.40913117e-01,\n",
       "       9.12124693e-01, 1.55849671e+00, 6.08591020e-01, 2.68487722e-01,\n",
       "       2.17481351e+00, 1.99098802e+00, 1.91770387e+00, 2.10112286e+00,\n",
       "       3.61622632e-01, 5.31490505e-01, 7.84737110e-01, 7.98666477e-01,\n",
       "       1.41794074e+00, 4.41148251e-01, 3.29095840e+00, 7.20990658e-01,\n",
       "       1.20461440e+00, 2.33416224e+00, 6.23414695e-01, 4.21765223e-02,\n",
       "       3.90057683e+00, 3.07486981e-01, 9.97689486e-01, 1.28982460e+00,\n",
       "       6.82095408e-01, 7.13032067e-01, 2.02509475e+00, 8.57928276e-01,\n",
       "       7.02569112e-02, 2.50551198e-02, 6.96034729e-01, 5.81475794e-01,\n",
       "       2.01887637e-01, 3.59929466e+00, 2.21356209e-02, 3.57323587e-02,\n",
       "       2.05820411e-01, 3.81770842e-02, 1.66701710e+00, 2.77359277e-01,\n",
       "       7.79761553e-01, 3.47891629e-01, 5.85491300e-01, 1.18751705e+00,\n",
       "       1.06834745e+00, 3.00960571e-01, 8.29692423e-01, 2.75424790e+00,\n",
       "       4.71731305e-01, 9.43295956e-01, 1.11527598e+00, 7.23516285e-01,\n",
       "       1.00502300e+00, 1.14371765e+00, 1.77379000e+00, 1.75603700e+00,\n",
       "       8.30604553e-01, 6.61839724e-01, 9.29620147e-01, 6.62871122e-01,\n",
       "       5.74052751e-01, 3.00261521e+00, 2.66624987e-01, 1.95768833e+00,\n",
       "       9.97962713e-01, 8.92703176e-01, 8.48826110e-01, 2.25395218e-01,\n",
       "       1.08636215e-01, 5.66097319e-01, 2.19924375e-01, 1.52451968e+00,\n",
       "       9.40830469e-01, 1.07309148e-01, 7.91291356e-01, 9.60617244e-01,\n",
       "       1.31005299e+00, 3.32812786e+00, 4.09213901e-01, 7.20054448e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1['data/videos/work/0.mp4/output000003.png'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
