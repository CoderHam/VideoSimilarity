{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import knn_cnn_features\n",
    "import sound_similarity_inference\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen(\"ffmpeg -i data/videos/animals/2.mp4 -f wav -vn data/tmp/animals_0.wav\", \\\n",
    "                     stdout=subprocess.PIPE, shell=True)\n",
    "(output, err) = p.communicate()\n",
    "p_status = p.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if there is an audio channel. If not, the output audio stream will be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen(\"ffprobe -i data/videos/animals/0.mp4 -show_streams -select_streams a -loglevel error\"\\\n",
    "                     , stdout=subprocess.PIPE, shell=True)\n",
    "(output, err) = p.communicate()\n",
    "p_status = p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No audio channel'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"No audio channel\" if output.decode()=='' else \"Audio channels present:\"+output.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ffprobe -i data/videos/animals/0.mp4 -show_streams -select_streams a -loglevel error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen(\"ffprobe -i /home/hemant/Videos/Titans\\ -\\ Season\\ 1.mp4 -show_streams -select_streams a -loglevel error\", \\\n",
    "                     stdout=subprocess.PIPE, shell=True)\n",
    "(output, err) = p.communicate()\n",
    "p_status = p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Audio channels present:[STREAM]\\nindex=1\\ncodec_name=aac\\ncodec_long_name=AAC (Advanced Audio Coding)\\nprofile=LC\\ncodec_type=audio\\ncodec_time_base=1/44100\\ncodec_tag_string=mp4a\\ncodec_tag=0x6134706d\\nsample_fmt=fltp\\nsample_rate=44100\\nchannels=2\\nchannel_layout=stereo\\nbits_per_sample=0\\nid=N/A\\nr_frame_rate=0/0\\navg_frame_rate=0/0\\ntime_base=1/44100\\nstart_pts=0\\nstart_time=0.000000\\nduration_ts=114762752\\nduration=2602.329977\\nbit_rate=125588\\nmax_bit_rate=N/A\\nbits_per_raw_sample=N/A\\nnb_frames=112073\\nnb_read_frames=N/A\\nnb_read_packets=N/A\\nDISPOSITION:default=1\\nDISPOSITION:dub=0\\nDISPOSITION:original=0\\nDISPOSITION:comment=0\\nDISPOSITION:lyrics=0\\nDISPOSITION:karaoke=0\\nDISPOSITION:forced=0\\nDISPOSITION:hearing_impaired=0\\nDISPOSITION:visual_impaired=0\\nDISPOSITION:clean_effects=0\\nDISPOSITION:attached_pic=0\\nDISPOSITION:timed_thumbnails=0\\nTAG:creation_time=2018-12-03T23:09:27.000000Z\\nTAG:language=eng\\nTAG:handler_name=ISO Media file produced by Google Inc. Created on: 12/03/2018.\\n[/STREAM]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"No audio channel\" if output.decode()=='' else \"Audio channels present:\"+output.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen(\"ffmpeg -i /home/hemant/Videos/Titans\\ -\\ Season\\ 1.mp4 -f wav -vn data/tmp/animals_0.wav\", \\\n",
    "                     stdout=subprocess.PIPE, shell=True)\n",
    "(output, err) = p.communicate()\n",
    "p_status = p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The file is huge. Taking a small chunk of it and delete the larger chunk\n",
    "!ffmpeg -t 30 -i data/tmp/animals_0.wav data/tmp/mini_0.wav -loglevel error && rm animals_0.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample script to create a log_mel_spectrogram\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "sample_rate=16000\n",
    "window_size=20\n",
    "step_size=10\n",
    "eps=1e-10\n",
    "rate, data = wavfile.read('data/tmp/mini_0.wav')\n",
    "if data.ndim > 1 : # ignore  channels 2+\n",
    "    data = data[:, 0]\n",
    "nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "freqs, times, spec = signal.spectrogram(data,fs=sample_rate,window='hann',nperseg=nperseg,noverlap=noverlap)\n",
    "log_specgram = np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8267, 161)\n"
     ]
    }
   ],
   "source": [
    "print(log_specgram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"audioset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module **vggish_input** has a function **wavfile_to_examples** which returns the log_mel_spectrogram (after correction intro standard form) of the input **wav_file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vggish_input\n",
    "features_tensor = vggish_input.wavfile_to_examples(wav_file='data/tmp/mini_0.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "827 ms ± 20 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 96, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module **vggish_inference** has a function **main** which returns the vggish extracted embedding (from the log_mel_spectrogram that is in turn created by vggish_input) of the input **wav_file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from audioset/vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import vggish_inference\n",
    "embedding_batch, postprocessed_batch = vggish_inference.main(wav_file='data/tmp/mini_0.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.94 s ± 6.51 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $31$ is the time in seconds of the audio stream and $128$ is the dimensionality of the extracted vggish embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read extracted audioset embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob \n",
    "tf.enable_eager_execution()\n",
    "\n",
    "files = sorted(glob.glob('audioset/data/audioset_v1_embeddings/bal_train/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTfRecords(tfrecords_filename, verbose = False, std_frames=10):\n",
    "    multiple_audio_embedding = []\n",
    "    labels = []\n",
    "\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "    for string_record in record_iterator:\n",
    "        example = tf.train.SequenceExample.FromString(string_record)\n",
    "        label = np.array(example.context.feature['labels'].int64_list.value)\n",
    "        n_frames = len(example.feature_lists.feature_list['audio_embedding'].feature)\n",
    "        audio_embedding = []\n",
    "        for i in range(n_frames):\n",
    "            audio_embedding.append(tf.cast(tf.decode_raw(example.feature_lists.feature_list['audio_embedding']\\\n",
    "                        .feature[i].bytes_list.value[0],tf.uint8),tf.float32).numpy())\n",
    "        audio_embedding = np.array(audio_embedding)\n",
    "        \n",
    "        if n_frames==std_frames:\n",
    "            labels.append(label)\n",
    "            multiple_audio_embedding.append(audio_embedding)\n",
    "        if verbose:\n",
    "            print('labels: ' + str(label))\n",
    "            print(audio_embedding.shape)\n",
    "    return np.array(multiple_audio_embedding), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.1 ms, sys: 19 ms, total: 59.1 ms\n",
      "Wall time: 44.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time multiple_audio_embedding, labels = readTfRecords(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 10, 128), 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_audio_embedding.shape, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4070/4070 [01:04<00:00, 63.43it/s]\n"
     ]
    }
   ],
   "source": [
    "all_audio_embedding = np.zeros((22176,10,128))\n",
    "all_labels = []\n",
    "pos = 0\n",
    "for file in tqdm(files):\n",
    "    multiple_audio_embedding, labels = readTfRecords(file)\n",
    "    length = len(labels)\n",
    "    if multiple_audio_embedding.shape!=(0,):\n",
    "        try:\n",
    "            all_audio_embedding[pos:(pos+length),] = np.array(multiple_audio_embedding)\n",
    "            all_labels = all_labels + labels\n",
    "            pos+=length\n",
    "        except:\n",
    "            print(multiple_audio_embedding.shape,file, length)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_audio_embedding = all_audio_embedding[:pos,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21782, 10, 128), 21782)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_audio_embedding.shape, len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"audio_embeddings\": shape (21782, 10, 128), type \"<f8\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioset_h5f = h5py.File('audioset_balanced_features_vggish.h5', 'w')\n",
    "audioset_h5f.create_dataset('audio_embeddings', data=all_audio_embedding)\n",
    "audioset_h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('audioset_balanced_labels.npy', all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_labels = [item for sublist in all_labels for item in sublist]\n",
    "# from collections import Counter\n",
    "# Counter(flat_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for Sound Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audioset_h5f = h5py.File('audioset_balanced_features_vggish.h5', 'r')\n",
    "audio_embeddings = np.array(audioset_h5f['audio_embeddings'],dtype='float32')\n",
    "audioset_h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_labels = np.load('audioset_balanced_labels.npy')\n",
    "feature_labels = np.array([flab[0] for flab in feature_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21782, 10, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21782, 1280)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_audio_embeddings = audio_embeddings.reshape(audio_embeddings.shape[:-2] + (-1,))\n",
    "reshaped_audio_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 354 ms, sys: 221 ms, total: 576 ms\n",
      "Wall time: 575 ms\n"
     ]
    }
   ],
   "source": [
    "%time feature_indices = knn_cnn_features.run_knn_features(reshaped_audio_embeddings,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_videos = feature_labels[feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cls_accuracy(similar_videos, feature_labels, k=3):\n",
    "    accuracy = 0\n",
    "    for i, sim_vids in enumerate(similar_videos):\n",
    "        true_label = feature_labels[i]\n",
    "        for sim_vid in sim_vids:\n",
    "            pred_label = sim_vid\n",
    "            accuracy += np.sum(pred_label==true_label)/k\n",
    "    return accuracy/len(feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47364796621067323\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",get_cls_accuracy(similar_videos,feature_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(feature_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we see a class-wise accuracy of $47\\%$ for the $448$ classes of audioset. Although the accuarcy is not high, this can be attributed to the following:\n",
    "\n",
    "    1. The larger number of class labels i.e. nearly 500.\n",
    "    2. The fact that we have considered only the first class label for each of the audio clips.\n",
    "    3. All votes are beening considered for calculating accuracy and not just majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of labels (if considering all - not just first)\n",
    "len(set([item for sublist in feature_labels for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 ms, sys: 96 ms, total: 110 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%time feature_indices = knn_cnn_features.run_knn_features(reshaped_audio_embeddings,\\\n",
    "                                                    test_vectors=reshaped_audio_embeddings[:10],k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for getting K similar videos from a new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sound_similarity_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from audioset/vggish_model.ckpt\n",
      "CPU times: user 1.28 s, sys: 245 ms, total: 1.53 s\n",
      "Wall time: 940 ms\n"
     ]
    }
   ],
   "source": [
    "%time audio_embedding = sound_similarity_inference.embedding_from_audio('data/audio/v_ApplyEyeMakeup_g01_c01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_embeddings, audio_labels, true_indices = sound_similarity_inference.load_sound_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 373 ms, total: 1.49 s\n",
      "Wall time: 807 ms\n"
     ]
    }
   ],
   "source": [
    "%time similar_indices = sound_similarity_inference.similar_sound_embedding(audio_embeddings[:1],k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = sound_similarity_inference.label_from_index(similar_indices[0], true_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoke detector, smoke alarm' 'Alarm clock' 'Alarm clock' 'Boing'\n",
      " 'Emergency vehicle' 'Caw' 'Grunge' 'Music' 'Music' 'Silence'] \n",
      " ['Smoke detector, smoke alarm']\n"
     ]
    }
   ],
   "source": [
    "print(output[0],\"\\n\",output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with second wise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audioset_h5f = h5py.File('audioset_balanced_features_vggish.h5', 'r')\n",
    "audio_embeddings = np.array(audioset_h5f['audio_embeddings'],dtype='float32')\n",
    "audioset_h5f.close()\n",
    "    \n",
    "feature_labels = np.load('audioset_balanced_labels.npy')\n",
    "feature_labels = np.array([flab[0] for flab in feature_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_audio_embeddings = audio_embeddings.reshape(audio_embeddings.shape[:-3] + (-1,128))\n",
    "embedding_labels = np.array([i for i in feature_labels for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((217820, 128), 217820)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_audio_embeddings.shape, len(embedding_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.39 s, sys: 2.34 s, total: 7.73 s\n",
      "Wall time: 7.74 s\n"
     ]
    }
   ],
   "source": [
    "%time feature_indices = knn_cnn_features.run_knn_features(merged_audio_embeddings,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6625822544591378\n"
     ]
    }
   ],
   "source": [
    "similar_videos = embedding_labels[feature_indices]\n",
    "print(\"Accuracy:\",get_cls_accuracy(similar_videos,embedding_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a train test split for KNN (70:30) to test accuracy for second-level KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_audio_embeddings, embedding_labels, \\\n",
    "                                        test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 977 ms, sys: 479 ms, total: 1.46 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%time feature_indices = knn_cnn_features.run_knn_features(X_train,test_vectors=X_test,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43782327915966457\n"
     ]
    }
   ],
   "source": [
    "similar_videos = y_train[feature_indices]\n",
    "print(\"Accuracy:\",get_cls_accuracy(similar_videos,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ordered_unique(listed):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in listed if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[137, 211]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ordered_unique(similar_videos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time for $1$ queries over $200,000$ frames of $128$ dimensionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 5.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit feature_indices = knn_cnn_features.run_knn_features(merged_audio_embeddings,\\\n",
    "                                                        test_vectors=X_test[:1],k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Sound features from UCF101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = sorted(glob.glob(\"data/UCF101/*\"))\n",
    "ucf_classes = [vid.split('/')[-1].split('_')[1] for vid in videos]\n",
    "ucf_classes = sorted(list(set(ucf_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_emb_from_vid(vid_path, vid_name):\n",
    "    sound_similarity_inference.extract_audio_from_video(vid_path)\n",
    "    audio_embedding = sound_similarity_inference.embedding_from_audio(\"data/audio/\"+vid_name+\".wav\")\n",
    "    return audio_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13320/13320 [2:08:45<00:00,  1.72it/s]  \n"
     ]
    }
   ],
   "source": [
    "for vid_path in tqdm(videos):\n",
    "    vid_name = vid_path.split('/')[-1].split('.')[0]\n",
    "    try:\n",
    "        audio_embedding = audio_emb_from_vid(vid_path, vid_name)\n",
    "        np.save('data/audio/'+vid_name+'.npy', audio_embedding)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = sorted(glob.glob(\"data/audio/*.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.33 % of the videos in the UCF dataset have an audio channel\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f\" % (len(videos)*100/13320),\"% of the videos in the UCF dataset have an audio channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6837/6837 [00:20<00:00, 330.70it/s] \n"
     ]
    }
   ],
   "source": [
    "feature_vectors = None\n",
    "audio_labels = []\n",
    "for vid in tqdm(videos):\n",
    "    if type(feature_vectors) is not np.ndarray:\n",
    "        aud_emb = np.load(vid).astype('float32')\n",
    "        audio_labels = audio_labels + [vid]*aud_emb.shape[0]\n",
    "        feature_vectors = aud_emb\n",
    "    else:\n",
    "        aud_emb = np.load(vid).astype('float32')\n",
    "        audio_labels = audio_labels + [vid]*aud_emb.shape[0]\n",
    "        feature_vectors = np.vstack((feature_vectors, aud_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File('audio_sec_UCF_vggish.h5', 'w')\n",
    "h5f.create_dataset('feature_vectors', data=feature_vectors)\n",
    "h5f.create_dataset('feature_labels', data=np.array(audio_labels, dtype='S'))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second wise similarity UCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_file = h5py.File('audio_sec_UCF_vggish.h5', 'r')\n",
    "feature_labels = np.array([fl.decode() for fl in feature_file['feature_labels']])\n",
    "feature_vectors = np.array(feature_file['feature_vectors'])\n",
    "feature_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479 ms ± 7.27 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit feature_indices = knn_cnn_features.run_knn_features(feature_vectors,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cls_accuracy_ucf(similar_videos, feature_labels, k=3):\n",
    "    accuracy = 0\n",
    "    for i, sim_vids in enumerate(similar_videos):\n",
    "        true_label = feature_labels[i].split('_')[1]\n",
    "        for sim_vid in sim_vids:\n",
    "            pred_label = sim_vid.split('_')[1]\n",
    "            accuracy += np.sum(pred_label==true_label)/k\n",
    "    return accuracy/len(feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7794387394018154\n"
     ]
    }
   ],
   "source": [
    "similar_videos = feature_labels[feature_indices]\n",
    "print(\"Accuracy:\",get_cls_accuracy_ucf(similar_videos,feature_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a train test split for KNN (70:30) to test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, feature_labels, \\\n",
    "                                        test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 ms ± 1.74 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit feature_indices = knn_cnn_features.run_knn_features(X_train,test_vectors=X_test,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_indices = knn_cnn_features.run_knn_features(X_train,test_vectors=X_test,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.635109763142556\n"
     ]
    }
   ],
   "source": [
    "similar_videos = y_train[feature_indices]\n",
    "print(\"Accuracy:\",get_cls_accuracy_ucf(similar_videos,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similar_videos_flat = [item.split('_')[1] for sublist in similar_videos for item in sublist]\n",
    "y_test_flat = [item.split('_')[1] for item in y_test for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe4cc3d73c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test_flat, similar_videos_flat)\n",
    "cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(cnf_matrix, range(51),\n",
    "                  range(51))\n",
    "plt.figure(figsize = (20,14))\n",
    "sn.set(font_scale=0.1)#for label size\n",
    "sn.heatmap(df_cm, annot=False)# font size ,annot_kws={\"size\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111\n",
      "0.11382113821138211\n",
      "0.10298102981029811\n",
      "0.10023310023310024\n",
      "Kayaking -> BalanceBeam\n",
      "BabyCrawling -> BasketballDunk\n",
      "FrontCrawl -> BasketballDunk\n",
      "BoxingPunchingBag -> Bowling\n"
     ]
    }
   ],
   "source": [
    "notsogood = []\n",
    "for i, row in enumerate(cnf_matrix):\n",
    "    for j, colj in enumerate(row):\n",
    "        if colj > 0.1 and i!=j:\n",
    "            print(cnf_matrix[i,j])\n",
    "            notsogood.append([i,j])\n",
    "for nsgi in notsogood:\n",
    "    print(ucf_classes[nsgi[1]],\"->\",ucf_classes[nsgi[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
